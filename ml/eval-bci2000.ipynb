{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit, cross_val_score, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations, EpochsArray, create_info\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.time_frequency import psd_array_welch, psd_array_multitaper, stft\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.3.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.9.0\n",
      "Keras Version: 2.9.0\n",
      "\n",
      "Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n",
      "[Clang 14.0.6 ]\n",
      "Pandas 1.5.2\n",
      "Scikit-Learn 1.2.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# keras/tensorflow\n",
    "\n",
    "import sys\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization, Dropout\n",
    "from keras.regularizers import l2\n",
    "import keras_tuner as kt\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import nengo\n",
    "from nengo.utils.filter_design import cont2discrete\n",
    "import nengo_dl\n",
    "\n",
    "from keras_lmu import LMU\n",
    "import keras_spiking\n",
    "\n",
    "\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3725, 4, 23, 9)\n",
      "(3725, 9, 92)\n",
      "(466, 4, 23, 9)\n",
      "(466, 9, 92)\n"
     ]
    }
   ],
   "source": [
    "# load batch_stft.npy and train_idx.npy\n",
    "# reconstructed_stft = np.load('preprocessed_data/reconstructed_stft.npy')\n",
    "source_stft = np.load('preprocessed_data/source_stft.npy')\n",
    "test_idx = np.load('preprocessed_data/test_idx.npy')\n",
    "train_idx = np.load('preprocessed_data/train_idx.npy')\n",
    "labels = np.load('preprocessed_data/labels.npy')\n",
    "freqs = np.load('preprocessed_data/freq.npy')\n",
    "\n",
    "train_stft = source_stft[train_idx]\n",
    "test_stft = source_stft[test_idx]\n",
    "welch_test = np.mean(test_stft, axis=3)\n",
    "welch_train = np.mean(train_stft, axis=3)\n",
    "y_train = labels[train_idx]\n",
    "y_test = labels[test_idx]\n",
    "\n",
    "# initialize sequential data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# log psd features in sensorimotor range\n",
    "X_train = train_stft[:, :, np.logical_and(freqs >= 8, freqs <= 30), :]\n",
    "print(X_train.shape)\n",
    "\n",
    "# merge channel and fft axis (1, 2)\n",
    "# move time axis to position 1 from 2 (keras format)\n",
    "X_train = np.moveaxis(X_train.reshape(X_train.shape[0], -1, X_train.shape[-1]), 2, 1)\n",
    "X_train = scaler.fit_transform(X_train.reshape((X_train.shape[0]*X_train.shape[1],X_train.shape[2]))).reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2]))\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "X_test = test_stft[:, :, np.logical_and(freqs >= 8, freqs <= 30), :]\n",
    "print(X_test.shape)\n",
    "X_test = np.moveaxis(X_test.reshape(X_test.shape[0], -1, X_test.shape[-1]), 2, 1)\n",
    "X_test = scaler.transform(X_test.reshape((X_test.shape[0]*X_test.shape[1],X_test.shape[2]))).reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2]))\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LMU Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_lmu = keras.models.load_model('models/keras-lmu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3971 - accuracy: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3970595896244049, 0.9356223344802856]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_lmu.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 23ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94       233\n",
      "           1       0.93      0.94      0.94       233\n",
      "\n",
      "    accuracy                           0.94       466\n",
      "   macro avg       0.94      0.94      0.94       466\n",
      "weighted avg       0.94      0.94      0.94       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "y_pred = keras_lmu.predict(X_test)\n",
    "y_pred = (y_pred>0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anushmutyala/Documents/GitHub/Energy-Efficient-Decoding-of-EEG-Motor-Imagery-using-Spiking-Legendre-Memory-Units/keras-spiking/keras_spiking/model_energy.py:318: UserWarning: Layer 'LMU' already registered. Overwriting.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 26ms/step\n",
      "Layer (typ|Param #|J/inf (cpu|J/inf (loi|J/inf (gpu|Synop J/inf|Synop J/in|Neuron J/in|Neuron J/in\n",
      "----------|-------|----------|----------|----------|-----------|----------|-----------|-----------\n",
      "lmu_14 (LM|  12720|    0.0001|   4.9e-08|   3.6e-06|     0.0001|   3.6e-06|    5.5e-07|    1.9e-08\n",
      "dense_14 (|     65|   5.6e-07|   7.4e-10|   1.9e-08|    5.5e-07|   1.9e-08|    8.6e-09|      3e-10\n",
      "==================================================================================================\n",
      "Total energy per inference [Joules/inf] (cpu): 1.05e-04\n",
      "Total energy per inference [Joules/inf] (loihi): 4.98e-08\n",
      "Total energy per inference [Joules/inf] (gpu): 3.65e-06\n"
     ]
    }
   ],
   "source": [
    "@keras_spiking.ModelEnergy.register_layer(LMU)\n",
    "def LMU_stats(node):\n",
    "    input_d = 92\n",
    "    units = 64\n",
    "    order = 32\n",
    "\n",
    "    # Connections: three sets of connections (x->h, m->h, h->h)\n",
    "    connections_x_to_h = input_d * units\n",
    "    connections_m_to_h = order * units\n",
    "    connections_h_to_h = units * units\n",
    "    connections = connections_x_to_h + connections_m_to_h + connections_h_to_h\n",
    "\n",
    "    # Neurons: number of neurons in the LMU is equal to the number of units\n",
    "    neurons = units\n",
    "\n",
    "    return {\"connections\": connections, \"neurons\": neurons, \"spiking\": True}\n",
    "\n",
    "energy = keras_spiking.ModelEnergy(keras_lmu, example_data=X_test)\n",
    "energy.summary(\n",
    "     columns=(\n",
    "        \"name\",\n",
    "        \"params\",\n",
    "        \"energy cpu\",\n",
    "        \"energy loihi\",\n",
    "        \"energy gpu\",\n",
    "        \"synop_energy cpu\",\n",
    "        \"synop_energy gpu\",\n",
    "        \"neuron_energy cpu\",\n",
    "        \"neuron_energy gpu\",\n",
    "    ),\n",
    "    timesteps_per_inference=9,\n",
    "    dt=0.001,\n",
    "    print_warnings=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = keras.models.load_model('models/lstm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 12ms/step - loss: 0.3076 - accuracy: 0.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3075696527957916, 0.9356223344802856]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       233\n",
      "           1       0.94      0.93      0.94       233\n",
      "\n",
      "    accuracy                           0.94       466\n",
      "   macro avg       0.94      0.94      0.94       466\n",
      "weighted avg       0.94      0.94      0.94       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "y_pred = lstm.predict(X_test)\n",
    "y_pred = (y_pred>0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anushmutyala/Documents/GitHub/Energy-Efficient-Decoding-of-EEG-Motor-Imagery-using-Spiking-Legendre-Memory-Units/keras-spiking/keras_spiking/model_energy.py:318: UserWarning: Layer 'LSTM' already registered. Overwriting.\n",
      "  warnings.warn(\n",
      "/Users/anushmutyala/Documents/GitHub/Energy-Efficient-Decoding-of-EEG-Motor-Imagery-using-Spiking-Legendre-Memory-Units/keras-spiking/keras_spiking/model_energy.py:793: UserWarning: Cannot compute stats for layer of type 'BatchNormalization'.Use `ModelEnergy.register_layer` to register this layer.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 7ms/step\n",
      "Layer (type)      |Param #|J/inf (cpu)|J/inf (gpu)|Synop J/inf|Synop J/inf|Neuron J/in|Neuron J/in\n",
      "------------------|-------|-----------|-----------|-----------|-----------|-----------|-----------\n",
      "lstm (LSTM)       |  40192|    0.00034|    1.2e-05|    0.00034|    1.2e-05|    5.5e-07|    1.9e-08\n",
      "batch_normalizatio|    256|          0|          0|          0|          0|          0|          0\n",
      "dense_9 (Dense)   |     65|    5.6e-07|    1.9e-08|    5.5e-07|    1.9e-08|    8.6e-09|      3e-10\n",
      "==================================================================================================\n",
      "Total energy per inference [Joules/inf] (cpu): 3.45e-04\n",
      "Total energy per inference [Joules/inf] (gpu): 1.20e-05\n"
     ]
    }
   ],
   "source": [
    "@keras_spiking.ModelEnergy.register_layer(LSTM)\n",
    "def LSTM_stats(node):\n",
    "    input_d = 92\n",
    "    units = 64\n",
    "\n",
    "    # Connections: three sets of connections (input->cell, cell->cell, and input->output)\n",
    "    connections_input_to_cell = 4 * input_d * units\n",
    "    connections_cell_to_cell = 4 * units * units\n",
    "    connections = connections_input_to_cell + connections_cell_to_cell\n",
    "\n",
    "    # Neurons: number of neurons in the LSTM is equal to the number of units\n",
    "    neurons = units\n",
    "\n",
    "    return {\"connections\": connections, \"neurons\": neurons, \"spiking\": True}\n",
    "\n",
    "energy = keras_spiking.ModelEnergy(lstm, example_data=X_test)\n",
    "energy.summary(\n",
    "     columns=(\n",
    "        \"name\",\n",
    "        \"params\",\n",
    "        \"energy cpu\",\n",
    "        # \"energy loihi\",\n",
    "        \"energy gpu\",\n",
    "        \"synop_energy cpu\",\n",
    "        \"synop_energy gpu\",\n",
    "        \"neuron_energy cpu\",\n",
    "        \"neuron_energy gpu\",\n",
    "    ),\n",
    "    timesteps_per_inference=9,\n",
    "    dt=0.001,\n",
    "    print_warnings=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking LMU Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 9, 92) (466, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape labels to rank 3 as expected in Nengo)\n",
    "y_train_3 = y_train.reshape((y_train.shape[0], 1, 1))\n",
    "y_test_3 = y_test.reshape((y_test.shape[0], 1, 1))\n",
    "\n",
    "print(X_test.shape, y_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingLMUCell(nengo.Network):\n",
    "    def __init__(self, units, order, theta, input_d, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # compute the A and B matrices according to the LMU's mathematical derivation\n",
    "        # (see the paper for details)\n",
    "        Q = np.arange(order, dtype=np.float64)\n",
    "        R = (2 * Q + 1)[:, None] / theta\n",
    "        j, i = np.meshgrid(Q, Q)\n",
    "\n",
    "        A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
    "        B = (-1.0) ** Q[:, None] * R\n",
    "        C = np.ones((1, order))\n",
    "        D = np.zeros((1,))\n",
    "        \n",
    "#          here we are using zero-order hold(zoh) method to \n",
    "#        discretize the value of A and B \n",
    "        A, B, _, _, _ = cont2discrete((A, B, C, D), dt=1.0, method=\"zoh\")\n",
    "\n",
    "        with self:\n",
    "            nengo_dl.configure_settings(trainable=None)\n",
    "\n",
    "            # create objects corresponding to the x/u/m/h variables in the above diagram\n",
    "            self.x = nengo.Node(size_in=input_d)\n",
    "            self.u = nengo.Node(size_in=1)\n",
    "            self.m = nengo.Node(size_in=order)\n",
    "#             self.h = nengo_dl.TensorNode(tf.nn.relu, shape_in=(units,), pass_time=False)\n",
    "            self.h = nengo.Ensemble(units, 1, \n",
    "                                    #neuron_type=nengo.RegularSpiking(nengo.Tanh(tau_ref=0.001)), \n",
    "                                    neuron_type=nengo.Tanh(tau_ref=1), \n",
    "                                    gain=np.ones(units), bias=np.zeros(units)).neurons  \n",
    "\n",
    "#             compute u_t from the above diagram. we have removed e_h and e_m as they\n",
    "#             are not needed in this task.\n",
    "            nengo.Connection(\n",
    "                self.x,\n",
    "                self.u,\n",
    "                transform=np.ones((1, input_d)),\n",
    "                synapse=None,\n",
    "            )\n",
    "\n",
    "            # compute m_t\n",
    "            # in this implementation we'll make A and B non-trainable, but they\n",
    "            # could also be optimized in the same way as the other parameters.\n",
    "            # note that setting synapse=0 (versus synapse=None) adds a one-timestep\n",
    "            # delay, so we can think of any connections with synapse=0 as representing\n",
    "            # value_{t-1}.\n",
    "            conn_A = nengo.Connection(\n",
    "                self.m,\n",
    "                self.m,\n",
    "                transform=A,\n",
    "                synapse=0,\n",
    "            )\n",
    "            self.config[conn_A].trainable = False\n",
    "            \n",
    "            conn_B = nengo.Connection(\n",
    "                self.u,\n",
    "                self.m,\n",
    "                transform=B,\n",
    "                synapse=None,\n",
    "            )\n",
    "            self.config[conn_B].trainable = False\n",
    "\n",
    "            # compute h_t\n",
    "            nengo.Connection(\n",
    "                self.x,\n",
    "                self.h,\n",
    "                transform=nengo_dl.dists.Glorot(),\n",
    "                synapse=None,\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                self.h,\n",
    "                self.h,\n",
    "                transform=nengo_dl.dists.Glorot(),\n",
    "                synapse=0,\n",
    "            )\n",
    "            nengo.Connection(\n",
    "                self.m,\n",
    "                self.h,\n",
    "                transform=nengo_dl.dists.Glorot(),\n",
    "                synapse=None,\n",
    "            )\n",
    "            \n",
    "with nengo.Network(seed=0) as net:\n",
    "    nengo_dl.configure_settings(\n",
    "        trainable=None,\n",
    "        stateful=None,\n",
    "        keep_history=False,\n",
    "    )\n",
    "\n",
    "    inp = nengo.Node((np.zeros(X_train.shape[-1])))\n",
    "\n",
    "    lmu = SpikingLMUCell(\n",
    "        units=64,\n",
    "        order=32,\n",
    "        theta=X_train.shape[1],\n",
    "        input_d=X_train.shape[-1],\n",
    "    )\n",
    "    net.config[lmu.h.ensemble].trainable = False\n",
    "    \n",
    "    conn = nengo.Connection(inp, lmu.x, synapse=None)\n",
    "    net.config[conn].trainable = False \n",
    "\n",
    "    out = nengo.Node(size_in=1) #changed to 1\n",
    "    nengo.Connection(lmu.h, out, transform=nengo_dl.dists.Glorot(), synapse=None)\n",
    "   \n",
    "    # p_inp = nengo.Probe(inp, label = \"input\")\n",
    "    # p_lmu = nengo.Probe(lmu.h, label = \"lmu\")\n",
    "    # p = nengo.Probe(out, label = \"output\") \n",
    "    p = nengo.Probe(out)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"keras_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " node (InputLayer)              [(1, None, 92)]      0           []                               \n",
      "                                                                                                  \n",
      " n_steps (InputLayer)           [(1, 1)]             0           []                               \n",
      "                                                                                                  \n",
      " TensorGraph (TensorGraph)      [(1, None, 1),       13244       ['node[0][0]',                   \n",
      "                                 (1,)]                            'n_steps[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,244\n",
      "Trainable params: 12,188\n",
      "Non-trainable params: 1,056\n",
      "__________________________________________________________________________________________________\n",
      "466/466 [==============================] - 13s 27ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       233\n",
      "           1       0.93      0.88      0.91       233\n",
      "\n",
      "    accuracy                           0.91       466\n",
      "   macro avg       0.91      0.91      0.91       466\n",
      "weighted avg       0.91      0.91      0.91       466\n",
      "\n",
      "Final test accuracy: 90.99\n"
     ]
    }
   ],
   "source": [
    "with nengo_dl.Simulator(net, minibatch_size=y_test[0], unroll_simulation=3, progress_bar=False) as sim:\n",
    "    sim.compile(\n",
    "        loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    sim.keras_model.summary()\n",
    "    sim.load_params(\"models/spikingLMU_params\")\n",
    "\n",
    "    test_pred = sim.predict(X_test)\n",
    "    # print(list(test_pred.values())[0].shape)\n",
    "\n",
    "    y_pred = (list(test_pred.values())[0].flatten()>0.5).astype(int)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # evaluate the model on the test set\n",
    "    test_acc = sim.evaluate(X_test, y_test_3, verbose=0)[\"probe_accuracy\"]\n",
    "    print(f\"Final test accuracy: {test_acc * 100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
